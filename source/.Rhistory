AccuracyPerLabel(confusion.matrix.kmeans.model, kmeans.set)
#Binary measures
Sensitivity(confusion.matrix.kmeans.model) * 100
Especificity(confusion.matrix.kmeans.model) * 100
Precision(confusion.matrix.kmeans.model) * 100
matrix.centers = FindCentersKmeans(set = kmeans.set, clusters = 2,
iterations = 30, iter.max = 100)
#Training the absolute model
matrix.centers = matrix.centers/30
kmeans.model = kmeans(kmeans.set[,1:(ncol(kmeans.set)-1)], centers = 2,
iter.max = 100)
#Ordering prediction
prediction = OrderKmeans(kmeans.model)
#Creating confusion matrix
confusion.matrix.kmeans.model = table(Real = kmeans.set[,ncol(kmeans.set)],
Prediction = prediction)
#Printing confusiopn matrix
confusion.matrix.kmeans.model
#Calculating accuracy
accuracy.kmeans.model = mean(prediction == kmeans.set[,ncol(kmeans.set)])
#Printing accuracy
accuracy.kmeans.model*100
#Printing error rate
AccuracyPerLabel(confusion.matrix.kmeans.model, kmeans.set)
#Binary measures
Sensitivity(confusion.matrix.kmeans.model) * 100
ErrorRate(accuracy.kmeans.model)
Especificity(confusion.matrix.kmeans.model) * 100
#Printing accuracy per labbel
Precision(confusion.matrix.kmeans.model) * 100
matrix.centers = FindCentersKmeans(set = kmeans.set, clusters = 2,
iterations = 100, iter.max = 100)
#Training the absolute model
matrix.centers = matrix.centers/30
kmeans.model = kmeans(kmeans.set[,1:(ncol(kmeans.set)-1)], centers = matrix.centers,
iter.max = 100)
#Ordering prediction
prediction = OrderKmeans(kmeans.model)
#Creating confusion matrix
confusion.matrix.kmeans.model = table(Real = kmeans.set[,ncol(kmeans.set)],
Prediction = prediction)
#Printing confusiopn matrix
confusion.matrix.kmeans.model
#Calculating accuracy
accuracy.kmeans.model = mean(prediction == kmeans.set[,ncol(kmeans.set)])
#Printing accuracy
accuracy.kmeans.model*100
#Printing error rate
ErrorRate(accuracy.kmeans.model)
#Printing accuracy per labbel
AccuracyPerLabel(confusion.matrix.kmeans.model, kmeans.set)
#Binary measures
Sensitivity(confusion.matrix.kmeans.model) * 100
Especificity(confusion.matrix.kmeans.model) * 100
Precision(confusion.matrix.kmeans.model) * 100
matrix.centers = FindCentersKmeans(set = kmeans.set, clusters = 2,
iterations = 100, iter.max = 100)
#Training the absolute model
matrix.centers = matrix.centers/100
kmeans.model = kmeans(kmeans.set[,1:(ncol(kmeans.set)-1)], centers = matrix.centers,
iter.max = 100)
#Ordering prediction
prediction = OrderKmeans(kmeans.model)
#Creating confusion matrix
confusion.matrix.kmeans.model = table(Real = kmeans.set[,ncol(kmeans.set)],
Prediction = prediction)
#Printing confusiopn matrix
confusion.matrix.kmeans.model
#Calculating accuracy
accuracy.kmeans.model = mean(prediction == kmeans.set[,ncol(kmeans.set)])
#Printing accuracy
accuracy.kmeans.model*100
#Printing error rate
ErrorRate(accuracy.kmeans.model)
#Printing accuracy per labbel
AccuracyPerLabel(confusion.matrix.kmeans.model, kmeans.set)
#Binary measures
Sensitivity(confusion.matrix.kmeans.model) * 100
Especificity(confusion.matrix.kmeans.model) * 100
Precision(confusion.matrix.kmeans.model) * 100
rm(list = ls())
#Loading packages
library("e1071")
library("nnet")
#Loading functions
source("functions/functions.R")
#Loading best objects
results.nn = readRDS("normal_model/NN/nn_results.rds")
best.model = readRDS("normal_model/NN/nn_best_model.rds")
best.testingset = readRDS("normal_model/NN/nn_best_testing_set.rds")
best.predictions = readRDS("normal_model/NN/nn_best_predictions.rds")
best.accuracy = readRDS("normal_model/NN/nn_best_accuracy.rds")
#Showing all results
results.nn
#Calculating the mean of the results
mean(results.nn) * 100
#Calculating the confusion matrix with the last model created
confusion.matrix.nn = table(Real = best.testingset[,ncol(best.testingset)],
Prediction = best.predictions)
#Showing confusion matrix
confusion.matrix.nn
best.accuracy * 100
ErrorRate(best.accuracy) * 100
#Showing accuracy per label
AccuracyPerLabel(confusion.matrix.nn, best.testingset)
#Confusion matrix Attack vs Normal
attack.normal.confusion.matrix = AttackNormalConfusionMatrix(best.testingset,
best.predictions)
attack.normal.confusion.matrix
#Binary measures
Sensitivity(attack.normal.confusion.matrix) * 100
Especificity(attack.normal.confusion.matrix) * 100
Precision(attack.normal.confusion.matrix) * 100
#ROC Curve
probabilities = predict(best.model,
best.testingset[, 1:(ncol(best.testingset)-1)])
#Generating Curve ROC
prob.vector = ExtractProbabilities(probabilities)
prob.vector.ordered = order(prob.vector, decreasing = TRUE)
prob.vector = prob.vector[prob.vector.ordered]
labels.roc = as.character(best.testingset[,ncol(best.testingset)])
labels.roc[labels.roc != "normal"] = "Attack"
labels.roc = labels.roc[prob.vector.ordered]
generate_ROC(prob.vector, labels.roc, "Attack")
#Adding the second level with K-Means
kmeans.set = best.testingset[best.predictions == "normal",]
dim(kmeans.set)
kmeans.set[,ncol(kmeans.set)] = as.character(kmeans.set[,ncol(kmeans.set)])
kmeans.set[kmeans.set[,ncol(kmeans.set)] != "normal",ncol(kmeans.set)] = "Attack"
SumLabels(kmeans.set, ncol(kmeans.set))
#Finding best centers
matrix.centers = FindCentersKmeans(set = kmeans.set, clusters = 2,
iterations = 100, iter.max = 100)
#Training the absolute model
matrix.centers = matrix.centers/100
kmeans.model = kmeans(kmeans.set[,1:(ncol(kmeans.set)-1)], centers = matrix.centers,
iter.max = 100)
#Ordering prediction
prediction = OrderKmeans(kmeans.model)
#Creating confusion matrix
confusion.matrix.kmeans.model = table(Real = kmeans.set[,ncol(kmeans.set)],
Prediction = prediction)
#Printing confusiopn matrix
confusion.matrix.kmeans.model
#Calculating accuracy
accuracy.kmeans.model = mean(prediction == kmeans.set[,ncol(kmeans.set)])
#Printing accuracy
accuracy.kmeans.model*100
#Printing error rate
ErrorRate(accuracy.kmeans.model)
#Printing accuracy per labbel
AccuracyPerLabel(confusion.matrix.kmeans.model, kmeans.set)
#Binary measures
Sensitivity(confusion.matrix.kmeans.model) * 100
Especificity(confusion.matrix.kmeans.model) * 100
Precision(confusion.matrix.kmeans.model) * 100
rm(list = ls())
source('~/Repos/source/normal_model/SVM/testing_model_svm.R', echo=TRUE)
setwd("C:/Users/deyban.perez/Documents/Repos/source") #Windows
rm(list = ls())
setwd("C:/Users/deyban.perez/Documents/Repos/source") #Windows
#Loading packages
require("e1071")
library("nnet")
#Loading functions
source("functions/functions.R")
#Loading best things
results.svm = readRDS("normal_model/SVM/svm_results.rds")
best.model = readRDS("normal_model/SVM/svm_best_model.rds")
best.testingset = readRDS("normal_model/SVM/svm_best_testing_set.rds")
best.predictions = readRDS("normal_model/SVM/svm_best_predictions.rds")
best.accuracy = readRDS("normal_model/SVM/svm_best_accuracy.rds")
#Showing all results
results.svm
#Calculating the mean of the results
mean(results.svm)
#Calculating the confusion matrix with the last model created
confusion.matrix.svm = table(Real = best.testingset[,ncol(best.testingset)],
Prediction = best.predictions)
#Showing confusion matrix
confusion.matrix.svm
best.accuracy * 100
ErrorRate(best.accuracy) * 100
#Showing accuracy per label
AccuracyPerLabel(confusion.matrix.svm, best.testingset)
#Confusion matrix Attack vs Normal
attack.normal.confusion.matrix = AttackNormalConfusionMatrix(best.testingset,
best.predictions)
#Binary measures
Sensitivity(attack.normal.confusion.matrix) * 100
Especificity(attack.normal.confusion.matrix) * 100
Precision(attack.normal.confusion.matrix) * 100
#ROC Curve
probabilities = predict(best.model,
best.testingset[, 1:(ncol(best.testingset)-1)],
probability = TRUE)
#Generating Curve ROC
prob.vector = ExtractProbabilities(attr(probabilities, "probabilities"))
prob.vector.ordered = order(prob.vector, decreasing = TRUE)
prob.vector = prob.vector[prob.vector.ordered]
labels.roc = as.character(best.testingset[,ncol(best.testingset)])
labels.roc[labels.roc != "normal"] = "Attack"
labels.roc = labels.roc[prob.vector.ordered]
generate_ROC(prob.vector, labels.roc, "Attack")
#Adding the sceond level with K-Means
kmeans.set = best.testingset[best.predictions == "normal",]
dim(kmeans.set)
kmeans.set[,ncol(kmeans.set)] = as.character(kmeans.set[,ncol(kmeans.set)])
kmeans.set[kmeans.set[,ncol(kmeans.set)] != "normal",ncol(kmeans.set)] = "Attack"
SumLabels(kmeans.set, ncol(kmeans.set))
#Finding best centers
matrix.centers = FindCentersKmeans(set = kmeans.set, clusters = 2,
iterations = 100, iter.max = 100)
#Training the absolute model
matrix.centers = matrix.centers/100
kmeans.model = kmeans(kmeans.set[,1:(ncol(kmeans.set)-1)], centers = matrix.centers,
iter.max = 100)
#Ordering prediction
prediction = OrderKmeans(kmeans.model)
#Creating confusion matrix
confusion.matrix.kmeans.model = table(Real = kmeans.set[,ncol(kmeans.set)],
Prediction = prediction)
#Printing confusiopn matrix
confusion.matrix.kmeans.model
#Calculating accuracy
accuracy.kmeans.model = mean(prediction == kmeans.set[,ncol(kmeans.set)])
#Printing accuracy
accuracy.kmeans.model*100
#Printing error rate
ErrorRate(accuracy.kmeans.model)
#Printing accuracy per labbel
AccuracyPerLabel(confusion.matrix.kmeans.model, kmeans.set)
#Binary measures
Sensitivity(confusion.matrix.kmeans.model) * 100
Especificity(confusion.matrix.kmeans.model) * 100
Precision(confusion.matrix.kmeans.model) * 100
rm(list = ls())
setwd("C:/Users/deyban.perez/Documents/Repos/source") #Windows
#Loading packages
library("e1071")
library("nnet")
#Loading functions
source("functions/functions.R")
#Loading best objects
results.nn = readRDS("normal_model/NN/nn_results.rds")
best.model = readRDS("normal_model/NN/nn_best_model.rds")
best.testingset = readRDS("normal_model/NN/nn_best_testing_set.rds")
best.predictions = readRDS("normal_model/NN/nn_best_predictions.rds")
best.accuracy = readRDS("normal_model/NN/nn_best_accuracy.rds")
#Showing all results
results.nn
#Calculating the mean of the results
mean(results.nn) * 100
#Calculating the confusion matrix with the last model created
confusion.matrix.nn = table(Real = best.testingset[,ncol(best.testingset)],
Prediction = best.predictions)
#Showing confusion matrix
confusion.matrix.nn
best.accuracy * 100
ErrorRate(best.accuracy) * 100
#Showing accuracy per label
AccuracyPerLabel(confusion.matrix.nn, best.testingset)
#Confusion matrix Attack vs Normal
attack.normal.confusion.matrix = AttackNormalConfusionMatrix(best.testingset,
best.predictions)
attack.normal.confusion.matrix
#Binary measures
Sensitivity(attack.normal.confusion.matrix) * 100
Especificity(attack.normal.confusion.matrix) * 100
Precision(attack.normal.confusion.matrix) * 100
#ROC Curve
probabilities = predict(best.model,
best.testingset[, 1:(ncol(best.testingset)-1)])
#Generating Curve ROC
prob.vector = ExtractProbabilities(probabilities)
prob.vector.ordered = order(prob.vector, decreasing = TRUE)
prob.vector = prob.vector[prob.vector.ordered]
labels.roc = as.character(best.testingset[,ncol(best.testingset)])
labels.roc[labels.roc != "normal"] = "Attack"
labels.roc = labels.roc[prob.vector.ordered]
generate_ROC(prob.vector, labels.roc, "Attack")
#Adding the second level with K-Means
kmeans.set = best.testingset[best.predictions == "normal",]
dim(kmeans.set)
kmeans.set[,ncol(kmeans.set)] = as.character(kmeans.set[,ncol(kmeans.set)])
kmeans.set[kmeans.set[,ncol(kmeans.set)] != "normal",ncol(kmeans.set)] = "Attack"
SumLabels(kmeans.set, ncol(kmeans.set))
#Finding best centers
matrix.centers = FindCentersKmeans(set = kmeans.set, clusters = 2,
iterations = 100, iter.max = 100)
#Training the absolute model
matrix.centers = matrix.centers/100
kmeans.model = kmeans(kmeans.set[,1:(ncol(kmeans.set)-1)], centers = matrix.centers,
iter.max = 100)
#Ordering prediction
prediction = OrderKmeans(kmeans.model)
#Creating confusion matrix
confusion.matrix.kmeans.model = table(Real = kmeans.set[,ncol(kmeans.set)],
Prediction = prediction)
#Printing confusiopn matrix
confusion.matrix.kmeans.model
#Calculating accuracy
accuracy.kmeans.model = mean(prediction == kmeans.set[,ncol(kmeans.set)])
#Printing accuracy
accuracy.kmeans.model*100
#Printing error rate
ErrorRate(accuracy.kmeans.model)
#Printing accuracy per labbel
AccuracyPerLabel(confusion.matrix.kmeans.model, kmeans.set)
#Binary measures
Sensitivity(confusion.matrix.kmeans.model) * 100
Especificity(confusion.matrix.kmeans.model) * 100
Precision(confusion.matrix.kmeans.model) * 100
rm(list = ls())
setwd("C:/Users/deyban.perez/Documents/Repos/source") #Windows
#Loading functions
source("functions/functions.R")
#Loading dataset
dataset.training = read.csv("../dataset/NSLKDD_Training_New.csv",
sep = ",", header = TRUE)
#Removing unnecesary labels
dataset = dataset.training
dataset$Label_Normal_TypeAttack = NULL
dataset$Label_Num_Classifiers = NULL
#Assigning classes to the data
for (i in 1 : (ncol(dataset) -2) )
dataset[,i] = as.numeric(dataset[,i])
for (i in (ncol(dataset) -1):ncol(dataset) )
dataset[,i] = as.factor(dataset[,i])
#Splitting set
dataset.two = dataset[-(ncol(dataset)-1)]
dataset.five = dataset[-ncol(dataset)]
#scaling sets
dataset$Label_Normal_or_Attack = NULL
dataset = ScaleSet(dataset)
dataset.two = ScaleSet(dataset.two)
dataset.five = ScaleSet(dataset.five)
#Codo de Jambu
IIC.Hartigan = vector(mode = "numeric", length = 30)
IIC.Lloyd = vector(mode = "numeric", length = 30)
IIC.Forgy = vector(mode = "numeric", length = 30)
IIC.MacQueen = vector(mode = "numeric", length = 30)
for (k in 1:30)
{
groups = kmeans(dataset[,ncol(dataset)-2], k, iter.max = 100, algorithm = "Hartigan-Wong")
IIC.Hartigan[k] = groups$tot.withinss
groups = kmeans(dataset[,ncol(dataset)-2], k, iter.max = 100, algorithm = "Lloyd")
IIC.Lloyd[k] = groups$tot.withinss
groups = kmeans(dataset[,ncol(dataset)-2], k, iter.max = 100, algorithm = "Forgy")
IIC.Forgy[k] = groups$tot.withinss
groups = kmeans(dataset[,ncol(dataset)-2], k, iter.max = 100, algorithm = "MacQueen")
IIC.MacQueen[k] = groups$tot.withinss
}
plot(IIC.Hartigan, col = "blue", type = "b", pch = 19)
points(IIC.Lloyd, col = "red", type = "b", pch = 19)
points(IIC.Forgy, col = "green", type = "b", pch = 19)
points(IIC.MacQueen, col = "magenta", type = "b", pch= 19)
legend("topright", legend = c("Hartigan", "Lloyd", "Forgy", "MacQueen"),
col = c("blue","red", "green", "magenta"), pch = 19)
#Testing the models
#Five class model
results.five = vector(mode = "numeric", length = 10)
best.accuracy.five = 0
for (i in 1:length(results.five))
{
set.seed(i)
model.kmeans.five = kmeans(dataset.five[,1:(ncol(dataset.five)-1)],
5, iter.max = 100)
prediction.five = OrderKmeans(model.kmeans.five)
accuracy.five = mean(prediction.five == dataset.five$Label)
results.five[i] = accuracy.five
if(best.accuracy.five < accuracy.five)
{
best.prediction.five = prediction.five
best.accuracy.five = accuracy.five
}
}
#Printing results
results.five
#Calculating mean of results
mean(results.five)
#Creating confusion matrix
confusion.matrix.five = table(Real = dataset.five$Label,
Prediction = best.prediction.five)
#Printing confusion matrix
confusion.matrix.five
#Printig accuracy rate and error rate
best.accuracy.five*100
ErrorRate(best.accuracy.five)*100
#Showing accuracy per label
AccuracyPerLabel(confusion.matrix.five, dataset.five)
#Confusion matrix Attack vs Normal
attack.normal.confusion.matrix.five = AttackNormalConfusionMatrix(dataset.five,
best.prediction.five)
attack.normal.confusion.matrix.five
#Binary measures
Sensitivity(attack.normal.confusion.matrix.five) * 100
Especificity(attack.normal.confusion.matrix.five) * 100
Precision(attack.normal.confusion.matrix.five) * 100
#################################################################################
#Two class model
results.two = vector(mode = "numeric", length = 10)
best.accuracy.two = 0
for (i in 1:length(results.two))
{
set.seed(i)
model.kmeans.two = kmeans(dataset.two[,1:(ncol(dataset.two)-1)],
2, iter.max = 100)
prediction.two = OrderKmeans(model.kmeans.two)
accuracy.two = mean(prediction.two == dataset.two$Label)
results.two[i] = accuracy.two
if(best.accuracy.two < accuracy.two)
{
best.prediction.two = prediction.two
best.accuracy.two = accuracy.two
}
}
#Printing results
results.two
#Calculating mean of results
mean(results.two)
#Creating confusion matrix
confusion.matrix.two = table(Real = dataset.two$Label,
Prediction = best.prediction.two)
#Printing confusion matrix
confusion.matrix.two
#Printig accuracy rate and error rate
best.accuracy.two*100
ErrorRate(best.accuracy.two)*100
#Showing accuracy per label
AccuracyPerLabel(confusion.matrix.two, dataset.two)
#Binary measures
Sensitivity(confusion.matrix.two) * 100
Especificity(confusion.matrix.two) * 100
Precision(confusion.matrix.two) * 100
results.two
mean(results.two)
setwd("C:/Users/deyban.perez/Documents/Repos/source") #Windows
setwd("C:/Users/deyban.perez/Documents/Repos/source") #Windows
rm(list = ls())
setwd("C:/Users/deyban.perez/Documents/Repos/source") #Windows
results.svm = readRDS("normal_model/SVM/Tests/svm_results.rds")
rm(list = ls())
setwd("C:/Users/deyban.perez/Documents/Repos/source") #Windows
setwd("C:/Users/deyban.perez/Documents/Repos/source") #Windows
results.svm = readRDS("normal_model/SVM/Tests/svm_results.rds")
rm(list = ls())
setwd("C:/Users/deyban.perez/Documents/Repos/source") #Windows
rm(list = ls())
#setwd("/home/dperez/Documents/Repos/Tesis/source")
#setwd("/home/dperez/Tesis/source")
setwd("C:/Users/deyban.perez/Documents/Repos/source") #Windows
#Loading packages
library("e1071")
library("nnet")
#Loading functions
source("functions/functions.R")
#Loading datasets
dataset.training = read.csv("../dataset/NSLKDD_Training_New.csv",
sep = ",", header = TRUE)
dataset.testing = read.csv("../dataset/NSLKDD_Testing_New.csv",
sep = ",", header = TRUE)
#removing unecesary labels in training set
dataset.training$Label_Normal_TypeAttack = NULL
dataset.training$Label_Num_Classifiers = NULL
dataset.training$Label_Normal_or_Attack = NULL
#removing unecesary labels in testing set
dataset.testing$Label_Normal_TypeAttack = NULL
dataset.testing$Label_Num_Classifiers = NULL
dataset.train$Label_Normal_or_Attack = NULL
#Assigning classes to the data
for (i in 1 : (ncol(dataset.training) -1) )
{
dataset.training[,i] = as.numeric(dataset.training[,i])
dataset.testing[,i] = as.numeric(dataset.testing[,i])
}
dataset.training[,ncol(dataset.training)] = as.factor(dataset.training[,ncol(dataset.training)])
dataset.testing[,ncol(dataset.testing)] = as.factor(dataset.testing[,ncol(dataset.testing)])
rm(list = ls())
#setwd("/home/dperez/Documents/Repos/Tesis/source")
#setwd("/home/dperez/Tesis/source")
setwd("C:/Users/deyban.perez/Documents/Repos/source") #Windows
#Loading packages
library("e1071")
library("nnet")
#Loading functions
source("functions/functions.R")
#Loading datasets
dataset.training = read.csv("../dataset/NSLKDD_Training_New.csv",
sep = ",", header = TRUE)
dataset.testing = read.csv("../dataset/NSLKDD_Testing_New.csv",
sep = ",", header = TRUE)
#removing unecesary labels in training set
dataset.training$Label_Normal_TypeAttack = NULL
dataset.training$Label_Num_Classifiers = NULL
dataset.training$Label_Normal_or_Attack = NULL
#removing unecesary labels in testing set
dataset.testing$Label_Normal_TypeAttack = NULL
dataset.testing$Label_Num_Classifiers = NULL
dataset.testing$Label_Normal_or_Attack = NULL
#Assigning classes to the data
for (i in 1 : (ncol(dataset.training) -1) )
{
dataset.training[,i] = as.numeric(dataset.training[,i])
dataset.testing[,i] = as.numeric(dataset.testing[,i])
}
dataset.training[,ncol(dataset.training)] = as.factor(dataset.training[,ncol(dataset.training)])
dataset.testing[,ncol(dataset.testing)] = as.factor(dataset.testing[,ncol(dataset.testing)])
names(dataset.training)
dataset.training = ScaleSet(dataset.training)
dataset.testing = ScaleSet(dataset.testing)
names(dataset.training)
