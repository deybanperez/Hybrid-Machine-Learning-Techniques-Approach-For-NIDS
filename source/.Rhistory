rm(list = ls())
setwd("/home/dperez/Documents/Repos/Tesis/source")
source("functions/functions.R")
require("factoextra")
dataset = dataset.training
dataset.training = read.csv("../dataset/NSLKDD_Training_New.csv",
sep = ",", header = TRUE)
source("functions/functions.R")
library("factoextra")
dataset = dataset.training
dataset$Label_Normal_TypeAttack = NULL
dataset$Label_Num_Classifiers = NULL
dataset$Label_Normal_or_Attack = NULL
#Cambiando el tipo de dato de las columnas
for (i in 1:(ncol(dataset)-1))
dataset[,i] = as.numeric(dataset[,i])
dataset[,ncol(dataset)] = as.factor(dataset[,ncol(dataset)])
#Escalando las variables predictoras
dataset = ScaleSet(dataset)
summary(pca)
pca = prcomp(dataset[,-41], scale. = TRUE)
summary(pca)
std.deviation = pca$sdev
PC.variance = std.deviation^2
PR.variance = PC.variance/sum(PC.variance)
cum.variance = cumsum(PR.variance) * 100
summary.pca = data.frame(std_deviation = std.deviation,
PC_variance = PC.variance,
PR_variance = PR.variance,
cum_variance = cum.variance)
summary.pca
plot(summary.pca$cum_variance,
ylab = "Cumulative Proportion",
xlab = "Number of Principal Components",
type = "b", col = "blue")
rm(list = ls())
setwd("/home/dperez/Documents/Repos/Tesis/source")
