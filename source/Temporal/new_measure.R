#Setting work directory
rm(list = ls())

#Loading packages
library("nnet")

#Loading functions
source("source/functions/functions.R")

#Loading Testing set
testing.set = read.csv("dataset/NSLKDD_Testing_New.csv",
                       sep = ",", header = TRUE)

type.attack = testing.set$Label_Normal_TypeAttack

#Removing unncessary features from testing set
testing.set$Label_Normal_TypeAttack = NULL
testing.set$Label_Num_Classifiers = NULL
testing.set$Label_Normal_or_Attack = NULL

#Scaling the set
testing.set = ScaleSet(testing.set)

#Selecting GFR features
nn.gfr = readRDS("source/feature_selection/NN/results_GFR.rds")
nn.gfr = rownames(nn.gfr)[1:19]

#Extracting info
Label = testing.set$Label

#Creating new DF
testing.set = testing.set[, nn.gfr]
testing.set = cbind(testing.set, Label = Label)

#loading results from training
results = readRDS("source/final_model/testing_set/list_results_19_features_30_neurons.rds")

#Extracting results
training.time = results[[1]]
model = results[[2]]

#Initializing the time
start.time.predictions = Sys.time()

#Making predictions
predictions = predict(model, testing.set[, 1:(ncol(testing.set)-1)], type = "class")

#Capturing the total time
total.time.predictions = Sys.time() - start.time.predictions
total.time.predictions
################################################################################
################################################################################
########################## New region ##########################################
################################################################################

#Calculating the proportinon of new attacks and knew attacks detected
#Finding true positives
true.positive.vector = predictions == testing.set$Label
#Loading names of new attacks
diff.attacks = readRDS(file = "source/Temporal/diff_attacks.rds")
#Locating positions of new attacks inside testing set 
new.attacks.vector = which(type.attack %in% diff.attacks)
#Calculating true positive proportion predictions on new attacks
true.positive.vector.new = true.positive.vector[new.attacks.vector]
length(true.positive.vector.new)
new.attacks.detected = sum(true.positive.vector.new)
new.attacks.detected
new.attacks.detected / length(new.attacks.vector) * 100

#Calculating true positive proportion on knew attacks
knew.attacks.detected = sum(true.positive.vector[testing.set$Label != "normal"]) - new.attacks.detected
knew.attacks.detected
total.attacks = sum(testing.set$Label != "normal")
total.knew.attacks = total.attacks - length(new.attacks.vector)
total.knew.attacks
knew.attacks.detected / total.knew.attacks * 100
  
################################################################################
################################################################################
########################## End new region ######################################
################################################################################  
#Confusion Matrix
confusion.matrix = table(Real = testing.set[,ncol(testing.set)],
                         Prediction = predictions)

#Accuracy
accuracy = mean(testing.set[,ncol(testing.set)] == predictions)
accuracy * 100
ErrorRate(accuracy) * 100

#Printing Accuracy per label
AccuracyPerLabel(confusion.matrix, testing.set)

# Confusion matrix Attack vs normal
attack.normal.confusion.matrix = AttackNormalConfusionMatrix(testing.set, predictions)
attack.normal.confusion.matrix

#Binary measures
Accuracy(attack.normal.confusion.matrix) * 100
Sensitivity(attack.normal.confusion.matrix) * 100
Especificity(attack.normal.confusion.matrix) * 100
Precision(attack.normal.confusion.matrix) * 100

#Calculating probabilities
probabilities = predict(model, testing.set[, 1:(ncol(testing.set)-1)])

#Generating ROC Curve
roc.data = DataROC(testing.set, probabilities, predictions)
generate_ROC(roc.data$Prob, roc.data$Label, roc.data$Prediction)

#Adding the second level with k-means
type.attack.kmeans = type.attack[predictions == "normal"]
kmeans.set = testing.set[predictions == "normal", ]
kmeans.set[,ncol(kmeans.set)] = as.character(kmeans.set[,ncol(kmeans.set)])
kmeans.set[kmeans.set[,ncol(kmeans.set)] != "normal",ncol(kmeans.set)] = "Attack"
SumLabels(kmeans.set, ncol(kmeans.set))

#Finding k-Means Centers
start.time.kmeans.training = Sys.time()
matrix.centers = FindCentersKmeans(set = kmeans.set, clusters = 2,
                                   iterations = 100, iter.max = 100)

#training the final model
matrix.centers = matrix.centers/100
total.time.kmeans.training = Sys.time() - start.time.kmeans.training

start.time.kmeans.predictions = Sys.time()
kmeans.model = kmeans(kmeans.set[,1:(ncol(kmeans.set)-1)], centers = matrix.centers,
                      iter.max = 100)

total.time.kmeans.predictions = Sys.time() - start.time.kmeans.predictions

#Ordering prediction
predictions = OrderKmeans(kmeans.model)

#Creating confusion matrix
confusion.matrix.kmeans.model = table(Real = kmeans.set[,ncol(kmeans.set)],
                                      Prediction = predictions)

#Printing confusiopn matrix
confusion.matrix.kmeans.model

#Calculating accuracy
accuracy.kmeans.model = mean(predictions == kmeans.set[,ncol(kmeans.set)])

#Printing accuracy
accuracy.kmeans.model*100

#Printing error rate
ErrorRate(accuracy.kmeans.model)*100

#Printing accuracy per labbel
AccuracyPerLabel(confusion.matrix.kmeans.model, kmeans.set)

#Binary mesuares
Sensitivity(confusion.matrix.kmeans.model) * 100
Especificity(confusion.matrix.kmeans.model) * 100
Precision(confusion.matrix.kmeans.model) * 100

#######################################################################
#######################################################################
######################### New region ##################################
#######################################################################
#######################################################################
true.positive.kmeans = predictions == kmeans.set$Label
length(true.positive.kmeans)

new.attacks.vector.kmeans = which(type.attack.kmeans %in% diff.attacks)
length(new.attacks.vector.kmeans) 
#Calculating true positive proportion predictions on new attacks
true.positive.new.kmeans = true.positive.kmeans[new.attacks.vector.kmeans]
new.attacks.detected.kmeans = sum(true.positive.new.kmeans)
new.attacks.detected.kmeans
new.attacks.detected.kmeans / length(new.attacks.vector.kmeans) * 100

#Calculating true positive proportion on knew attacks
knew.attacks.detected.kmeans = sum(true.positive.kmeans[kmeans.set$Label != "normal"]) - new.attacks.detected.kmeans
knew.attacks.detected.kmeans
total.attacks.kmeans = sum(kmeans.set$Label != "normal")
total.knew.attacks.kmeans = total.attacks.kmeans - length(new.attacks.vector.kmeans)
total.knew.attacks.kmeans
knew.attacks.detected.kmeans / total.knew.attacks.kmeans * 100


#Total statistics
confusion.matrix.two.labels = TwoLevelsCM(attack.normal.confusion.matrix, confusion.matrix.kmeans.model)
confusion.matrix.two.labels
accuracy.total = Accuracy(confusion.matrix.two.labels)
accuracy.total * 100
ErrorRate(accuracy.total) * 100
Sensitivity(confusion.matrix.two.labels) * 100
Especificity(confusion.matrix.two.labels) * 100
Precision(confusion.matrix.two.labels) * 100
total.time.predictions + total.time.kmeans.predictions
training.time + total.time.kmeans.training