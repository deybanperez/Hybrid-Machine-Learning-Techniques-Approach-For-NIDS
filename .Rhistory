#Setting work directory
rm(list = ls())
#Loading packages
library("nnet")
#Loading functions
source("source/functions/functions.R")
#Loading dataset
dataset.training = read.csv("dataset/NSLKDD_Training_New.csv",
sep = ",", header = TRUE)
#Removing unnecesary labels
dataset = dataset.training
dataset$Label_Normal_TypeAttack = NULL
dataset$Label_Num_Classifiers = NULL
dataset$Label_Normal_or_Attack = NULL
#Assigning classes to the data
for (i in 1 : (ncol(dataset) -1) )
dataset[,i] = as.numeric(dataset[,i])
dataset[,ncol(dataset)] = as.factor(dataset[,ncol(dataset)])
#Scaling set
dataset = ScaleSet(dataset)
#Selecting GFR features
nn.gfr = readRDS("source/feature_selection/NN/results_GFR.rds")
nn.gfr = rownames(nn.gfr)[1:9]
#Extracting info
Label = dataset$Label
#Creating new DF
dataset = dataset[, nn.gfr]
dataset = cbind(dataset, Label = Label)
#Starting 10-fold cross validation
cv.sets = CVSet(dataset, k = 10, seed = 22)
length(cv.sets)
#Initializing some variables
results = vector(mode = "numeric", length = 10)
list.results = list(0, 0, 0, 0)
names(list.results) = c("results", "best_model", "best_testing_set", "best_predictions")
best.accuracy = 0
#Loading best number of hidden neurons
hidden.neurons = readRDS("source/parameter_selection/NN/GFR/tuned_model.rds")
hidden.neurons = hidden.neurons$best.parameters$size
hidden.neurons
for (i in 1:10)
{
#Extracting sets
testingset = as.data.frame(cv.sets[[i]])
trainingset = cv.sets
trainingset[[i]] = NULL
trainingset = do.call(rbind, trainingset)
#NN Model
model = nnet(Label ~ .,
data = trainingset,
size = hidden.neurons,
maxit = 100)
#Making predictions
predictions = predict(model, testingset[, 1:(ncol(testingset)-1)], type = "class")
#Calculating accuracy
accuracy = mean(testingset[, ncol(testingset)] == predictions)
#Storing results
results[i] = accuracy
#Storing best results
if(best.accuracy < accuracy)
{
list.results$best_model = model
list.results$best_testing_set = testingset
list.results$best_predictions = predictions
best.accuracy = accuracy
}
}
#Storing results
list.results$results = results
#Saving list of objects
saveRDS(list.results, "source/tuned_model/GFR/NN/training_set/list_results.rds")
rm(list = ls())
library("nnet")
source("source/functions/functions.R")
list.results = readRDS("source/tuned_model/GFR/NN/training_set/list_results.rds")
list.results$results
mean(list.results$results) * 100
confusion.matrix = table(Real = list.results$best_testing_set[,ncol(list.results$best_testing_set)],
Prediction = list.results$best_predictions)
confusion.matrix
accuracy = mean(list.results$best_testing_set[,ncol(list.results$best_testing_set)] ==
list.results$best_predictions)
accuracy * 100
ErrorRate(accuracy) * 100
AccuracyPerLabel(confusion.matrix, list.results$best_testing_set)
attack.normal.confusion.matrix = AttackNormalConfusionMatrix(list.results$best_testing_set,
list.results$best_predictions)
rm(list = ls())
library("nnet")
source("source/functions/functions.R")
list.results = readRDS("source/tuned_model/GFR/NN/training_set/list_results.rds")
list.results$results
mean(list.results$results) * 100
confusion.matrix = table(Real = list.results$best_testing_set[,ncol(list.results$best_testing_set)],
Prediction = list.results$best_predictions)
confusion.matrix
accuracy = mean(list.results$best_testing_set[,ncol(list.results$best_testing_set)] ==
list.results$best_predictions)
accuracy * 100
ErrorRate(accuracy) * 100
AccuracyPerLabel(confusion.matrix, list.results$best_testing_set)
#Setting work directory
rm(list = ls())
#Loading packages
library("e1071")
#Loading functions
source("source/functions/functions.R")
#Loading Testing set
testing.set = read.csv("dataset/NSLKDD_Testing_New.csv",
sep = ",", header = TRUE)
#Removing unncessary features from testing set
testing.set$Label_Normal_TypeAttack = NULL
testing.set$Label_Num_Classifiers = NULL
testing.set$Label_Normal_or_Attack = NULL
#Scaling the set
testing.set = ScaleSet(testing.set)
#Selecting GFR features
svm.gfr = readRDS("source/feature_selection/SVM/results_GFR.rds")
svm.gfr = rownames(svm.gfr)[1:9]
#Extracting info
Label = testing.set$Label
#Creating new DF
testing.set = testing.set[, svm.gfr]
testing.set = cbind(testing.set, Label = Label)
#loading results from training
results = readRDS("source/tuned_model/GFR/SVM/testing_set/list_results.rds")
#Extracting results
training.time = results[[1]]
model = results[[2]]
#Initializing the time
start.time.predictions = Sys.time()
#Making predictions
predictions = predict(model, testing.set[, 1:(ncol(testing.set)-1)], type = "class")
#Capturing the total time
total.time.predictions = Sys.time() - start.time.predictions
total.time.predictions
#Confusion Matrix
confusion.matrix = table(Real = testing.set[,ncol(testing.set)],
Prediction = predictions)
confusion.matrix
#Accuracy
accuracy = mean(testing.set[,ncol(testing.set)] == predictions)
accuracy * 100
ErrorRate(accuracy) * 100
#Printing Accuracy per label
AccuracyPerLabel(confusion.matrix, testing.set)
# Confusion matrix Attack vs normal
attack.normal.confusion.matrix = AttackNormalConfusionMatrix(testing.set, predictions)
attack.normal.confusion.matrix
#Binary measures
Sensitivity(attack.normal.confusion.matrix) * 100
Especificity(attack.normal.confusion.matrix) * 100
Precision(attack.normal.confusion.matrix) * 100
#Calculating probabilities
probabilities = predict(model, testing.set[, 1:(ncol(testing.set)-1)], probability = TRUE)
#Generating ROC Curve
roc.data = DataROC(testing.set, attr(probabilities, "probabilities"), predictions)
generate_ROC(roc.data$Prob, roc.data$Label, roc.data$Prediction)
kmeans.set = testing.set[predictions == "normal", ]
dim(kmeans.set)
View(kmeans.set)
kmeans.set[,ncol(kmeans.set)] = as.character(kmeans.set[,ncol(kmeans.set)])
kmeans.set[kmeans.set[,ncol(kmeans.set)] != "normal",ncol(kmeans.set)] = "Attack"
SumLabels(kmeans.set, ncol(kmeans.set))
#Finding k-Means Centers
start.time.kmeans.training = Sys.time()
matrix.centers = FindCentersKmeans(set = kmeans.set, clusters = 2,
iterations = 100, iter.max = 100)
#training the final model
matrix.centers = matrix.centers/100
total.time.kmeans.training = Sys.time() - start.time.kmeans.training
View(kmeans.set[,1:(ncol(kmeans.set)-1)])
#Setting work directory
rm(list = ls())
#Loading packages
library("e1071")
#Loading functions
source("source/functions/functions.R")
#Loading dataset
dataset.training = read.csv("dataset/NSLKDD_Training_New.csv",
sep = ",", header = TRUE)
#Removing unnecesary labels
dataset = dataset.training
dataset$Label_Normal_TypeAttack = NULL
dataset$Label_Num_Classifiers = NULL
dataset$Label_Normal_or_Attack = NULL
#Assigning classes to the data
for (i in 1 : (ncol(dataset) -1) )
dataset[,i] = as.numeric(dataset[,i])
dataset[,ncol(dataset)] = as.factor(dataset[,ncol(dataset)])
#Scaling set
dataset = ScaleSet(dataset)
#Selecting GFR features
svm.gfr = readRDS("source/feature_selection/SVM/results_GFR.rds")
svm.gfr = rownames(svm.gfr)[1:9]
#Extracting info
Label = dataset$Label
#Creating new DF
dataset = dataset[, svm.gfr]
dataset = cbind(dataset, Label = Label)
#Starting 10-fold cross validation
cv.sets = CVSet(dataset, k = 10, seed = 22)
length(cv.sets)
#Initializing some variables
results = vector(mode = "numeric", length = 10)
list.results = list(0, 0, 0, 0)
names(list.results) = c("results", "best_model", "best_testing_set", "best_predictions")
best.accuracy = 0
for (i in 1:10)
{
#Extracting sets
testingset = as.data.frame(cv.sets[[i]])
trainingset = cv.sets
trainingset[[i]] = NULL
trainingset = do.call(rbind, trainingset)
#SVM Model
model = svm(Label ~ .,
data = trainingset,
kernel = "radial",
scale = FALSE,
probability = TRUE)
#Making predictions
predictions = predict(model, testingset[, 1:(ncol(testingset)-1)], type = "class")
#Calculating accuracy
accuracy = mean(testingset[, ncol(testingset)] == predictions)
#Storing results
results[i] = accuracy
#Storing best results
if(best.accuracy < accuracy)
{
list.results$best_model = model
list.results$best_testing_set = testingset
list.results$best_predictions = predictions
best.accuracy = accuracy
}
}
#Storing results
list.results$results = results
#Saving list of objects
saveRDS(list.results, "source/default_parameters/GFR/SVM/training_set/list_results.rds")
#Setting work directory
rm(list = ls())
#Loading packages
library("e1071")
#Loading functions
source("source/functions/functions.R")
#Loading dataset
dataset.training = read.csv("dataset/NSLKDD_Training_New.csv",
sep = ",", header = TRUE)
#Removing unnecesary labels
dataset = dataset.training
dataset$Label_Normal_TypeAttack = NULL
dataset$Label_Num_Classifiers = NULL
dataset$Label_Normal_or_Attack = NULL
#Assigning classes to the data
for (i in 1 : (ncol(dataset) -1) )
dataset[,i] = as.numeric(dataset[,i])
dataset[,ncol(dataset)] = as.factor(dataset[,ncol(dataset)])
#Scaling set
dataset = ScaleSet(dataset)
#Aplying PCA
pca = prcomp(dataset[, -41], scale. = TRUE)
dataset = cbind(as.data.frame(pca$x[,1:24]), Label = dataset$Label)
#Starting 10-fold cross validation
cv.sets = CVSet(dataset, k = 10, seed = 22)
length(cv.sets)
#Initializing some variables
results = vector(mode = "numeric", length = 10)
list.results = list(0, 0, 0, 0)
names(list.results) = c("results", "best_model", "best_testing_set", "best_predictions")
best.accuracy = 0
#Loading tuned parameters
tuned.parameters = readRDS("source/parameter_selection/SVM/PCA/tuned_model_24_features.rds")
tuned.cost = tuned.parameters$best.parameters$cost
tuned.gamma = tuned.parameters$best.parameters$gamma
tuned.cost
tuned.gamma
for (i in 1:10)
{
#Extracting sets
testingset = as.data.frame(cv.sets[[i]])
trainingset = cv.sets
trainingset[[i]] = NULL
trainingset = do.call(rbind, trainingset)
#SVM Model
model = svm(Label ~ .,
data = trainingset,
kernel = "radial",
cost = tuned.cost,
gamma = tuned.gamma,
scale = FALSE,
probability = TRUE)
#Making predictions
predictions = predict(model, testingset[, 1:(ncol(testingset)-1)], type = "class")
#Calculating accuracy
accuracy = mean(testingset[, ncol(testingset)] == predictions)
#Storing results
results[i] = accuracy
#Storing best results
if(best.accuracy < accuracy)
{
list.results$best_model = model
list.results$best_testing_set = testingset
list.results$best_predictions = predictions
best.accuracy = accuracy
}
}
#Storing results
list.results$results = results
#Saving list of objects
saveRDS(list.results, "source/tuned_model/PCA/SVM/training_set/list_results_24_features.rds")
#Setting work directory
rm(list = ls())
#Loading packages
library("nnet")
#Loading functions
source("source/functions/functions.R")
#Loading dataset
dataset.training = read.csv("dataset/NSLKDD_Training_New.csv",
sep = ",", header = TRUE)
#Removing unnecesary labels
dataset = dataset.training
dataset$Label_Normal_TypeAttack = NULL
dataset$Label_Num_Classifiers = NULL
dataset$Label_Normal_or_Attack = NULL
#Assigning classes to the data
for (i in 1 : (ncol(dataset) -1) )
dataset[,i] = as.numeric(dataset[,i])
dataset[,ncol(dataset)] = as.factor(dataset[,ncol(dataset)])
#Scaling set
dataset = ScaleSet(dataset)
#Selecting GFR features
nn.gfr = readRDS("source/feature_selection/NN/results_GFR.rds")
nn.gfr = rownames(nn.gfr)[1:19]
#Extracting info
Label = dataset$Label
#Creating new DF
dataset = dataset[, nn.gfr]
dataset = cbind(dataset, Label = Label)
#Starting 10-fold cross validation
cv.sets = CVSet(dataset, k = 10, seed = 22)
length(cv.sets)
#Initializing some variables
results = vector(mode = "numeric", length = 10)
list.results = list(0, 0, 0, 0)
names(list.results) = c("results", "best_model", "best_testing_set", "best_predictions")
best.accuracy = 0
for (i in 1:10)
{
#Extracting sets
testingset = as.data.frame(cv.sets[[i]])
trainingset = cv.sets
trainingset[[i]] = NULL
trainingset = do.call(rbind, trainingset)
#NN Model
model = nnet(Label ~ .,
data = trainingset,
size = 20,
maxit = 100)
#Making predictions
predictions = predict(model, testingset[, 1:(ncol(testingset)-1)], type = "class")
#Calculating accuracy
accuracy = mean(testingset[, ncol(testingset)] == predictions)
#Storing results
results[i] = accuracy
#Storing best results
if(best.accuracy < accuracy)
{
list.results$best_model = model
list.results$best_testing_set = testingset
list.results$best_predictions = predictions
best.accuracy = accuracy
}
}
#Storing results
list.results$results = results
#Saving list of objects
saveRDS(list.results, "source/default_parameters/GFR/NN/training_set/list_results_19_features.rds")
